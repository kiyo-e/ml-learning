{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sin波作成\n",
    "def sin(x, T=100):\n",
    "      return np.sin(2.0 * np.pi * x / T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ノイズ化\n",
    "def toy_problem(T=100, ampl=0.05):\n",
    "    x = np.arange(0, 2 * T + 1)\n",
    "    noise = ampl * np.random.uniform(low=1.0, high=1.0, size=len(x))\n",
    "    return sin(x) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "f = toy_problem(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_of_sequences = 2 * T\n",
    "maxlen = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, length_of_sequences - maxlen + 1):\n",
    "    data.append(f[i: i + maxlen])\n",
    "    target.append(f[i + maxlen])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data).reshape(len(data), maxlen, 1)\n",
    "Y = np.array(target).reshape(len(data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_train = int(len(data) * 0.9)\n",
    "N_validation = len(data) - N_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 25, 1)\n",
      "(176, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "158\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(data) )\n",
    "print(N_train)\n",
    "print(N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    train_test_split(X, Y, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = len(X[0][0])\n",
    "n_hidden = 20\n",
    "n_out = len(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(n_in)\n",
    "print(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name=None):\n",
    "    return np.random.normal(scale=.01, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden,\n",
    "                   kernel_initializer=weight_variable,\n",
    "                   input_shape=(maxlen, n_in)))\n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "model.add(Activation(\"linear\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 158 samples, validate on 18 samples\n",
      "Epoch 1/500\n",
      "158/158 [==============================] - 0s - loss: 0.4982 - val_loss: 0.4058\n",
      "Epoch 2/500\n",
      "158/158 [==============================] - 0s - loss: 0.4619 - val_loss: 0.3437\n",
      "Epoch 3/500\n",
      "158/158 [==============================] - 0s - loss: 0.3631 - val_loss: 0.2859\n",
      "Epoch 4/500\n",
      "158/158 [==============================] - 0s - loss: 0.3081 - val_loss: 0.2572\n",
      "Epoch 5/500\n",
      "158/158 [==============================] - 0s - loss: 0.2523 - val_loss: 0.2073\n",
      "Epoch 6/500\n",
      "158/158 [==============================] - 0s - loss: 0.2094 - val_loss: 0.1719\n",
      "Epoch 7/500\n",
      "158/158 [==============================] - 0s - loss: 0.1665 - val_loss: 0.1358\n",
      "Epoch 8/500\n",
      "158/158 [==============================] - 0s - loss: 0.1328 - val_loss: 0.1097\n",
      "Epoch 9/500\n",
      "158/158 [==============================] - 0s - loss: 0.0999 - val_loss: 0.0808\n",
      "Epoch 10/500\n",
      "158/158 [==============================] - 0s - loss: 0.0723 - val_loss: 0.0565\n",
      "Epoch 11/500\n",
      "158/158 [==============================] - 0s - loss: 0.0458 - val_loss: 0.0362\n",
      "Epoch 12/500\n",
      "158/158 [==============================] - 0s - loss: 0.0256 - val_loss: 0.0206\n",
      "Epoch 13/500\n",
      "158/158 [==============================] - 0s - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 14/500\n",
      "158/158 [==============================] - 0s - loss: 0.0127 - val_loss: 0.0097\n",
      "Epoch 15/500\n",
      "158/158 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0084\n",
      "Epoch 16/500\n",
      "158/158 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 17/500\n",
      "158/158 [==============================] - 0s - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 18/500\n",
      "158/158 [==============================] - 0s - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 19/500\n",
      "158/158 [==============================] - 0s - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 20/500\n",
      "158/158 [==============================] - 0s - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 21/500\n",
      "158/158 [==============================] - 0s - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 22/500\n",
      "158/158 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 23/500\n",
      "158/158 [==============================] - 0s - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 24/500\n",
      "158/158 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 25/500\n",
      "158/158 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0011ss: 0.0\n",
      "Epoch 26/500\n",
      "158/158 [==============================] - 0s - loss: 0.0011 - val_loss: 8.8500e-04\n",
      "Epoch 27/500\n",
      "158/158 [==============================] - 0s - loss: 9.3911e-04 - val_loss: 7.7320e-04\n",
      "Epoch 28/500\n",
      "158/158 [==============================] - 0s - loss: 7.0049e-04 - val_loss: 6.1619e-04\n",
      "Epoch 29/500\n",
      "158/158 [==============================] - 0s - loss: 4.6094e-04 - val_loss: 3.9537e-044.8291e\n",
      "Epoch 30/500\n",
      "158/158 [==============================] - 0s - loss: 3.2165e-04 - val_loss: 3.0466e-04\n",
      "Epoch 31/500\n",
      "158/158 [==============================] - 0s - loss: 2.2995e-04 - val_loss: 2.7172e-04\n",
      "Epoch 32/500\n",
      "158/158 [==============================] - 0s - loss: 1.7309e-04 - val_loss: 1.7167e-04\n",
      "Epoch 33/500\n",
      "158/158 [==============================] - 0s - loss: 1.4494e-04 - val_loss: 1.4022e-04\n",
      "Epoch 34/500\n",
      "158/158 [==============================] - 0s - loss: 1.1881e-04 - val_loss: 1.6224e-04\n",
      "Epoch 35/500\n",
      "158/158 [==============================] - 0s - loss: 1.2550e-04 - val_loss: 1.2142e-04\n",
      "Epoch 36/500\n",
      "158/158 [==============================] - 0s - loss: 8.6203e-05 - val_loss: 8.1195e-05\n",
      "Epoch 37/500\n",
      "158/158 [==============================] - 0s - loss: 5.7558e-05 - val_loss: 8.1129e-05\n",
      "Epoch 38/500\n",
      "158/158 [==============================] - 0s - loss: 5.6634e-05 - val_loss: 7.0932e-05\n",
      "Epoch 39/500\n",
      "158/158 [==============================] - 0s - loss: 4.7309e-05 - val_loss: 8.7807e-05\n",
      "Epoch 40/500\n",
      "158/158 [==============================] - 0s - loss: 5.5135e-05 - val_loss: 6.6550e-05\n",
      "Epoch 41/500\n",
      "158/158 [==============================] - 0s - loss: 4.3431e-05 - val_loss: 5.7532e-054.3124e-\n",
      "Epoch 42/500\n",
      "158/158 [==============================] - 0s - loss: 4.2457e-05 - val_loss: 5.9474e-05\n",
      "Epoch 43/500\n",
      "158/158 [==============================] - 0s - loss: 4.5354e-05 - val_loss: 5.4340e-05\n",
      "Epoch 44/500\n",
      "158/158 [==============================] - 0s - loss: 4.1303e-05 - val_loss: 5.4027e-05\n",
      "Epoch 45/500\n",
      "158/158 [==============================] - 0s - loss: 4.1698e-05 - val_loss: 5.2746e-05\n",
      "Epoch 46/500\n",
      "158/158 [==============================] - 0s - loss: 3.9407e-05 - val_loss: 5.7863e-05\n",
      "Epoch 47/500\n",
      "158/158 [==============================] - 0s - loss: 3.9032e-05 - val_loss: 5.8407e-05\n",
      "Epoch 48/500\n",
      "158/158 [==============================] - 0s - loss: 3.8780e-05 - val_loss: 5.3457e-05\n",
      "Epoch 49/500\n",
      "158/158 [==============================] - 0s - loss: 3.5612e-05 - val_loss: 6.0198e-05\n",
      "Epoch 50/500\n",
      "158/158 [==============================] - 0s - loss: 3.7455e-05 - val_loss: 4.8562e-05\n",
      "Epoch 51/500\n",
      "158/158 [==============================] - 0s - loss: 3.8541e-05 - val_loss: 5.6106e-05\n",
      "Epoch 52/500\n",
      "158/158 [==============================] - 0s - loss: 3.9968e-05 - val_loss: 4.3763e-05\n",
      "Epoch 53/500\n",
      "158/158 [==============================] - 0s - loss: 4.6622e-05 - val_loss: 9.7573e-054.6519e\n",
      "Epoch 54/500\n",
      "158/158 [==============================] - 0s - loss: 4.5855e-05 - val_loss: 5.5868e-05\n",
      "Epoch 55/500\n",
      "158/158 [==============================] - 0s - loss: 4.3267e-05 - val_loss: 4.5472e-05\n",
      "Epoch 56/500\n",
      "158/158 [==============================] - 0s - loss: 3.5447e-05 - val_loss: 5.3502e-05\n",
      "Epoch 57/500\n",
      "158/158 [==============================] - 0s - loss: 3.3410e-05 - val_loss: 5.6673e-05\n",
      "Epoch 58/500\n",
      "158/158 [==============================] - 0s - loss: 3.3665e-05 - val_loss: 4.3345e-05\n",
      "Epoch 59/500\n",
      "158/158 [==============================] - 0s - loss: 3.0785e-05 - val_loss: 3.6194e-05\n",
      "Epoch 60/500\n",
      "158/158 [==============================] - 0s - loss: 2.8991e-05 - val_loss: 4.0018e-05\n",
      "Epoch 61/500\n",
      "158/158 [==============================] - 0s - loss: 3.5258e-05 - val_loss: 5.0388e-05\n",
      "Epoch 62/500\n",
      "158/158 [==============================] - 0s - loss: 3.4246e-05 - val_loss: 3.7333e-05\n",
      "Epoch 63/500\n",
      "158/158 [==============================] - 0s - loss: 2.8452e-05 - val_loss: 3.5226e-05\n",
      "Epoch 64/500\n",
      "158/158 [==============================] - 0s - loss: 2.7850e-05 - val_loss: 3.4641e-05\n",
      "Epoch 65/500\n",
      "158/158 [==============================] - 0s - loss: 2.8012e-05 - val_loss: 3.3395e-05\n",
      "Epoch 66/500\n",
      "158/158 [==============================] - 0s - loss: 2.5022e-05 - val_loss: 3.8024e-05\n",
      "Epoch 67/500\n",
      "158/158 [==============================] - 0s - loss: 2.7347e-05 - val_loss: 3.6431e-05\n",
      "Epoch 68/500\n",
      "158/158 [==============================] - 0s - loss: 2.5923e-05 - val_loss: 3.0182e-05\n",
      "Epoch 69/500\n",
      "158/158 [==============================] - 0s - loss: 2.8216e-05 - val_loss: 2.9690e-05\n",
      "Epoch 70/500\n",
      "158/158 [==============================] - 0s - loss: 2.4197e-05 - val_loss: 3.1372e-05\n",
      "Epoch 71/500\n",
      "158/158 [==============================] - 0s - loss: 2.6314e-05 - val_loss: 3.9134e-05\n",
      "Epoch 72/500\n",
      "158/158 [==============================] - 0s - loss: 2.5030e-05 - val_loss: 2.6389e-05\n",
      "Epoch 73/500\n",
      "158/158 [==============================] - 0s - loss: 2.8417e-05 - val_loss: 2.6716e-05\n",
      "Epoch 74/500\n",
      "158/158 [==============================] - 0s - loss: 2.8725e-05 - val_loss: 2.6714e-05\n",
      "Epoch 75/500\n",
      "158/158 [==============================] - 0s - loss: 2.8944e-05 - val_loss: 2.5555e-05\n",
      "Epoch 76/500\n",
      "158/158 [==============================] - 0s - loss: 2.5979e-05 - val_loss: 3.5101e-05\n",
      "Epoch 77/500\n",
      "158/158 [==============================] - 0s - loss: 2.4206e-05 - val_loss: 2.8665e-05\n",
      "Epoch 78/500\n",
      "158/158 [==============================] - 0s - loss: 2.2411e-05 - val_loss: 4.4170e-05\n",
      "Epoch 79/500\n",
      "158/158 [==============================] - 0s - loss: 2.3322e-05 - val_loss: 2.4121e-05\n",
      "Epoch 80/500\n",
      "158/158 [==============================] - 0s - loss: 1.8787e-05 - val_loss: 2.6603e-05\n",
      "Epoch 81/500\n",
      "158/158 [==============================] - 0s - loss: 2.5500e-05 - val_loss: 2.2811e-05\n",
      "Epoch 82/500\n",
      "158/158 [==============================] - 0s - loss: 2.4008e-05 - val_loss: 2.5129e-05\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s - loss: 2.0150e-05 - val_loss: 3.4320e-05\n",
      "Epoch 84/500\n",
      "158/158 [==============================] - 0s - loss: 2.3114e-05 - val_loss: 2.7405e-05\n",
      "Epoch 85/500\n",
      "158/158 [==============================] - 0s - loss: 1.8919e-05 - val_loss: 2.2941e-05\n",
      "Epoch 86/500\n",
      "158/158 [==============================] - 0s - loss: 1.7492e-05 - val_loss: 2.4116e-05\n",
      "Epoch 87/500\n",
      "158/158 [==============================] - 0s - loss: 1.7853e-05 - val_loss: 2.2688e-05\n",
      "Epoch 88/500\n",
      "158/158 [==============================] - 0s - loss: 2.0024e-05 - val_loss: 2.1388e-05\n",
      "Epoch 89/500\n",
      "158/158 [==============================] - 0s - loss: 1.6231e-05 - val_loss: 2.4245e-05\n",
      "Epoch 90/500\n",
      "158/158 [==============================] - 0s - loss: 1.9949e-05 - val_loss: 2.1130e-05\n",
      "Epoch 91/500\n",
      "158/158 [==============================] - 0s - loss: 1.5604e-05 - val_loss: 2.3503e-05\n",
      "Epoch 92/500\n",
      "158/158 [==============================] - 0s - loss: 1.7659e-05 - val_loss: 2.1295e-05\n",
      "Epoch 93/500\n",
      "158/158 [==============================] - 0s - loss: 1.7900e-05 - val_loss: 2.6610e-05\n",
      "Epoch 94/500\n",
      "158/158 [==============================] - 0s - loss: 1.5703e-05 - val_loss: 1.7719e-05\n",
      "Epoch 95/500\n",
      "158/158 [==============================] - 0s - loss: 1.6033e-05 - val_loss: 1.9885e-05\n",
      "Epoch 96/500\n",
      "158/158 [==============================] - 0s - loss: 1.6752e-05 - val_loss: 1.6477e-05\n",
      "Epoch 97/500\n",
      "158/158 [==============================] - 0s - loss: 1.6297e-05 - val_loss: 1.9373e-05\n",
      "Epoch 98/500\n",
      "158/158 [==============================] - 0s - loss: 1.6606e-05 - val_loss: 1.6356e-05\n",
      "Epoch 99/500\n",
      "158/158 [==============================] - 0s - loss: 1.4354e-05 - val_loss: 1.7264e-05\n",
      "Epoch 100/500\n",
      "158/158 [==============================] - 0s - loss: 1.5350e-05 - val_loss: 1.6136e-05\n",
      "Epoch 101/500\n",
      "158/158 [==============================] - 0s - loss: 1.6748e-05 - val_loss: 1.5349e-05\n",
      "Epoch 102/500\n",
      "158/158 [==============================] - 0s - loss: 1.5628e-05 - val_loss: 1.5634e-05\n",
      "Epoch 103/500\n",
      "158/158 [==============================] - 0s - loss: 1.9944e-05 - val_loss: 3.3742e-05\n",
      "Epoch 104/500\n",
      "158/158 [==============================] - 0s - loss: 2.5615e-05 - val_loss: 1.4726e-05\n",
      "Epoch 105/500\n",
      "158/158 [==============================] - 0s - loss: 1.9478e-05 - val_loss: 1.5737e-05\n",
      "Epoch 106/500\n",
      "158/158 [==============================] - 0s - loss: 1.4336e-05 - val_loss: 1.4922e-05\n",
      "Epoch 107/500\n",
      "158/158 [==============================] - 0s - loss: 1.3176e-05 - val_loss: 1.4670e-05\n",
      "Epoch 108/500\n",
      "158/158 [==============================] - 0s - loss: 1.1810e-05 - val_loss: 1.2694e-05\n",
      "Epoch 109/500\n",
      "158/158 [==============================] - 0s - loss: 1.0460e-05 - val_loss: 2.6002e-05\n",
      "Epoch 110/500\n",
      "158/158 [==============================] - 0s - loss: 1.5702e-05 - val_loss: 1.5036e-05\n",
      "Epoch 111/500\n",
      "158/158 [==============================] - 0s - loss: 1.0413e-05 - val_loss: 1.3986e-05\n",
      "Epoch 112/500\n",
      "158/158 [==============================] - 0s - loss: 1.2587e-05 - val_loss: 2.2756e-05\n",
      "Epoch 113/500\n",
      "158/158 [==============================] - 0s - loss: 1.6132e-05 - val_loss: 1.5483e-05\n",
      "Epoch 114/500\n",
      "158/158 [==============================] - 0s - loss: 1.3162e-05 - val_loss: 1.1238e-05\n",
      "Epoch 115/500\n",
      "158/158 [==============================] - 0s - loss: 1.0985e-05 - val_loss: 1.1959e-05\n",
      "Epoch 116/500\n",
      "158/158 [==============================] - 0s - loss: 1.0638e-05 - val_loss: 1.0827e-05\n",
      "Epoch 117/500\n",
      "158/158 [==============================] - 0s - loss: 1.1152e-05 - val_loss: 1.1563e-05\n",
      "Epoch 118/500\n",
      "158/158 [==============================] - 0s - loss: 1.3364e-05 - val_loss: 1.7646e-05\n",
      "Epoch 119/500\n",
      "158/158 [==============================] - 0s - loss: 1.1441e-05 - val_loss: 1.3065e-05\n",
      "Epoch 120/500\n",
      "158/158 [==============================] - 0s - loss: 9.7528e-06 - val_loss: 1.1709e-05\n",
      "Epoch 121/500\n",
      "158/158 [==============================] - 0s - loss: 8.9570e-06 - val_loss: 1.1230e-05\n",
      "Epoch 122/500\n",
      "158/158 [==============================] - 0s - loss: 1.8640e-05 - val_loss: 1.9662e-05\n",
      "Epoch 123/500\n",
      "158/158 [==============================] - 0s - loss: 1.5126e-05 - val_loss: 2.2283e-05\n",
      "Epoch 124/500\n",
      "158/158 [==============================] - 0s - loss: 2.3259e-05 - val_loss: 2.4097e-05\n",
      "Epoch 125/500\n",
      "158/158 [==============================] - 0s - loss: 1.6261e-05 - val_loss: 1.6108e-05\n",
      "Epoch 126/500\n",
      "158/158 [==============================] - 0s - loss: 1.3131e-05 - val_loss: 9.5936e-06\n",
      "Epoch 127/500\n",
      "158/158 [==============================] - 0s - loss: 1.3686e-05 - val_loss: 1.1376e-05\n",
      "Epoch 128/500\n",
      "158/158 [==============================] - 0s - loss: 1.0022e-05 - val_loss: 1.0545e-059.8212e-0\n",
      "Epoch 129/500\n",
      "158/158 [==============================] - 0s - loss: 1.2009e-05 - val_loss: 2.4811e-05\n",
      "Epoch 130/500\n",
      "158/158 [==============================] - 0s - loss: 2.9473e-05 - val_loss: 8.5034e-06\n",
      "Epoch 131/500\n",
      "158/158 [==============================] - 0s - loss: 1.8168e-05 - val_loss: 2.0488e-05\n",
      "Epoch 132/500\n",
      "158/158 [==============================] - 0s - loss: 1.0916e-05 - val_loss: 1.1794e-05\n",
      "Epoch 133/500\n",
      "158/158 [==============================] - 0s - loss: 8.0875e-06 - val_loss: 8.1214e-06\n",
      "Epoch 134/500\n",
      "158/158 [==============================] - 0s - loss: 7.6935e-06 - val_loss: 7.7891e-06\n",
      "Epoch 135/500\n",
      "158/158 [==============================] - 0s - loss: 6.8637e-06 - val_loss: 7.5245e-06\n",
      "Epoch 136/500\n",
      "158/158 [==============================] - 0s - loss: 7.0073e-06 - val_loss: 7.0491e-06\n",
      "Epoch 137/500\n",
      "158/158 [==============================] - 0s - loss: 6.8051e-06 - val_loss: 7.2903e-06\n",
      "Epoch 138/500\n",
      "158/158 [==============================] - 0s - loss: 6.1945e-06 - val_loss: 6.9891e-06\n",
      "Epoch 139/500\n",
      "158/158 [==============================] - 0s - loss: 7.6850e-06 - val_loss: 8.0396e-06\n",
      "Epoch 140/500\n",
      "158/158 [==============================] - 0s - loss: 5.9880e-06 - val_loss: 8.6477e-06\n",
      "Epoch 141/500\n",
      "158/158 [==============================] - 0s - loss: 6.6631e-06 - val_loss: 6.5026e-06\n",
      "Epoch 142/500\n",
      "158/158 [==============================] - 0s - loss: 7.4543e-06 - val_loss: 6.9304e-06\n",
      "Epoch 143/500\n",
      "158/158 [==============================] - 0s - loss: 9.3441e-06 - val_loss: 1.4343e-05\n",
      "Epoch 144/500\n",
      "158/158 [==============================] - 0s - loss: 7.6203e-06 - val_loss: 6.2374e-06\n",
      "Epoch 145/500\n",
      "158/158 [==============================] - 0s - loss: 6.5788e-06 - val_loss: 7.2927e-06\n",
      "Epoch 146/500\n",
      "158/158 [==============================] - 0s - loss: 6.0410e-06 - val_loss: 7.4953e-06\n",
      "Epoch 147/500\n",
      "158/158 [==============================] - 0s - loss: 8.9019e-06 - val_loss: 1.5072e-05\n",
      "Epoch 148/500\n",
      "158/158 [==============================] - 0s - loss: 9.6950e-06 - val_loss: 1.2340e-05\n",
      "Epoch 149/500\n",
      "158/158 [==============================] - 0s - loss: 1.2456e-05 - val_loss: 9.4350e-06\n",
      "Epoch 150/500\n",
      "158/158 [==============================] - 0s - loss: 1.5698e-05 - val_loss: 1.5940e-05\n",
      "Epoch 151/500\n",
      "158/158 [==============================] - 0s - loss: 8.0763e-06 - val_loss: 7.1388e-06\n",
      "Epoch 152/500\n",
      "158/158 [==============================] - 0s - loss: 8.4548e-06 - val_loss: 7.2816e-06\n",
      "Epoch 153/500\n",
      "158/158 [==============================] - 0s - loss: 7.4497e-06 - val_loss: 5.1712e-06\n",
      "Epoch 154/500\n",
      "158/158 [==============================] - 0s - loss: 7.7862e-06 - val_loss: 7.2500e-06\n",
      "Epoch 155/500\n",
      "158/158 [==============================] - 0s - loss: 5.1922e-06 - val_loss: 6.3859e-06\n",
      "Epoch 156/500\n",
      "158/158 [==============================] - 0s - loss: 4.3773e-06 - val_loss: 5.0945e-06\n",
      "Epoch 157/500\n",
      "158/158 [==============================] - 0s - loss: 5.8614e-06 - val_loss: 8.8668e-06\n",
      "Epoch 158/500\n",
      "158/158 [==============================] - 0s - loss: 8.7824e-06 - val_loss: 4.5876e-06\n",
      "Epoch 159/500\n",
      "158/158 [==============================] - 0s - loss: 7.1707e-06 - val_loss: 6.7285e-06\n",
      "Epoch 160/500\n",
      "158/158 [==============================] - 0s - loss: 4.9114e-06 - val_loss: 4.0708e-06\n",
      "Epoch 161/500\n",
      "158/158 [==============================] - 0s - loss: 4.6749e-06 - val_loss: 6.5964e-06\n",
      "Epoch 162/500\n",
      "158/158 [==============================] - 0s - loss: 4.4326e-06 - val_loss: 4.7286e-06\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s - loss: 4.5259e-06 - val_loss: 3.9067e-06\n",
      "Epoch 164/500\n",
      "158/158 [==============================] - 0s - loss: 6.9831e-06 - val_loss: 9.2867e-06\n",
      "Epoch 165/500\n",
      "158/158 [==============================] - 0s - loss: 1.0681e-05 - val_loss: 1.2001e-05\n",
      "Epoch 166/500\n",
      "158/158 [==============================] - 0s - loss: 6.5689e-06 - val_loss: 4.6532e-06\n",
      "Epoch 167/500\n",
      "158/158 [==============================] - 0s - loss: 4.7538e-06 - val_loss: 4.1318e-06\n",
      "Epoch 168/500\n",
      "158/158 [==============================] - 0s - loss: 3.9871e-06 - val_loss: 3.5711e-06\n",
      "Epoch 169/500\n",
      "158/158 [==============================] - 0s - loss: 4.3018e-06 - val_loss: 5.2779e-06\n",
      "Epoch 170/500\n",
      "158/158 [==============================] - 0s - loss: 5.8250e-06 - val_loss: 1.1254e-05\n",
      "Epoch 171/500\n",
      "158/158 [==============================] - 0s - loss: 7.2046e-06 - val_loss: 1.2163e-05\n",
      "Epoch 172/500\n",
      "158/158 [==============================] - 0s - loss: 5.4111e-06 - val_loss: 4.4591e-06\n",
      "Epoch 173/500\n",
      "158/158 [==============================] - 0s - loss: 3.9718e-06 - val_loss: 3.6092e-06\n",
      "Epoch 174/500\n",
      "158/158 [==============================] - 0s - loss: 4.3539e-06 - val_loss: 3.8267e-06\n",
      "Epoch 175/500\n",
      "158/158 [==============================] - 0s - loss: 5.5520e-06 - val_loss: 7.6385e-06\n",
      "Epoch 176/500\n",
      "158/158 [==============================] - 0s - loss: 9.2430e-06 - val_loss: 3.6422e-06\n",
      "Epoch 177/500\n",
      "158/158 [==============================] - 0s - loss: 1.0324e-05 - val_loss: 4.3052e-06\n",
      "Epoch 178/500\n",
      "158/158 [==============================] - 0s - loss: 4.9807e-06 - val_loss: 4.8340e-06\n",
      "Epoch 179/500\n",
      "158/158 [==============================] - 0s - loss: 4.0228e-06 - val_loss: 3.2445e-06\n",
      "Epoch 180/500\n",
      "158/158 [==============================] - 0s - loss: 3.0726e-06 - val_loss: 4.5321e-06\n",
      "Epoch 181/500\n",
      "158/158 [==============================] - 0s - loss: 4.9744e-06 - val_loss: 4.2688e-06\n",
      "Epoch 182/500\n",
      "158/158 [==============================] - 0s - loss: 3.6127e-06 - val_loss: 3.0294e-06\n",
      "Epoch 183/500\n",
      "158/158 [==============================] - 0s - loss: 2.9706e-06 - val_loss: 3.9058e-06\n",
      "Epoch 184/500\n",
      "158/158 [==============================] - 0s - loss: 2.2604e-06 - val_loss: 4.3415e-06\n",
      "Epoch 185/500\n",
      "158/158 [==============================] - 0s - loss: 3.8974e-06 - val_loss: 3.9763e-06\n",
      "Epoch 186/500\n",
      "158/158 [==============================] - 0s - loss: 3.7811e-06 - val_loss: 2.3910e-06\n",
      "Epoch 187/500\n",
      "158/158 [==============================] - 0s - loss: 2.2593e-06 - val_loss: 3.2760e-06\n",
      "Epoch 188/500\n",
      "158/158 [==============================] - 0s - loss: 2.8150e-06 - val_loss: 4.3343e-06\n",
      "Epoch 189/500\n",
      "158/158 [==============================] - 0s - loss: 2.9146e-06 - val_loss: 2.9714e-06\n",
      "Epoch 190/500\n",
      "158/158 [==============================] - 0s - loss: 3.1554e-06 - val_loss: 5.6217e-06\n",
      "Epoch 191/500\n",
      "158/158 [==============================] - 0s - loss: 4.4590e-06 - val_loss: 4.0421e-06\n",
      "Epoch 192/500\n",
      "158/158 [==============================] - 0s - loss: 7.0859e-06 - val_loss: 2.1321e-06\n",
      "Epoch 193/500\n",
      "158/158 [==============================] - 0s - loss: 5.7034e-06 - val_loss: 4.8044e-06\n",
      "Epoch 194/500\n",
      "158/158 [==============================] - 0s - loss: 3.8124e-06 - val_loss: 5.4410e-06\n",
      "Epoch 195/500\n",
      "158/158 [==============================] - 0s - loss: 8.5596e-06 - val_loss: 4.3655e-05\n",
      "Epoch 196/500\n",
      "158/158 [==============================] - 0s - loss: 1.7562e-05 - val_loss: 1.3884e-05\n",
      "Epoch 197/500\n",
      "158/158 [==============================] - 0s - loss: 7.4711e-06 - val_loss: 3.9462e-06\n",
      "Epoch 198/500\n",
      "158/158 [==============================] - 0s - loss: 3.2756e-06 - val_loss: 2.1800e-06\n",
      "Epoch 199/500\n",
      "158/158 [==============================] - 0s - loss: 1.8546e-06 - val_loss: 4.1105e-06\n",
      "Epoch 200/500\n",
      "158/158 [==============================] - 0s - loss: 2.7508e-06 - val_loss: 2.0379e-06\n",
      "Epoch 201/500\n",
      "158/158 [==============================] - 0s - loss: 2.6997e-06 - val_loss: 1.8400e-06\n",
      "Epoch 202/500\n",
      "158/158 [==============================] - 0s - loss: 2.8575e-06 - val_loss: 2.8037e-06\n",
      "Epoch 203/500\n",
      "158/158 [==============================] - 0s - loss: 2.1790e-06 - val_loss: 3.3486e-06\n",
      "Epoch 204/500\n",
      "158/158 [==============================] - 0s - loss: 2.2344e-06 - val_loss: 4.8038e-06\n",
      "Epoch 205/500\n",
      "158/158 [==============================] - 0s - loss: 2.0888e-06 - val_loss: 1.7168e-06\n",
      "Epoch 206/500\n",
      "158/158 [==============================] - 0s - loss: 1.5264e-06 - val_loss: 1.5646e-06\n",
      "Epoch 207/500\n",
      "158/158 [==============================] - 0s - loss: 1.8064e-06 - val_loss: 3.9402e-06\n",
      "Epoch 208/500\n",
      "158/158 [==============================] - 0s - loss: 3.3828e-06 - val_loss: 1.9920e-06\n",
      "Epoch 209/500\n",
      "158/158 [==============================] - 0s - loss: 1.7588e-06 - val_loss: 1.4219e-06\n",
      "Epoch 210/500\n",
      "158/158 [==============================] - 0s - loss: 1.7614e-06 - val_loss: 2.0524e-06\n",
      "Epoch 211/500\n",
      "158/158 [==============================] - 0s - loss: 1.9832e-06 - val_loss: 1.6568e-06\n",
      "Epoch 212/500\n",
      "120/158 [=====================>........] - ETA: 0s - loss: 3.2958e-06"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, Y_validation),\n",
    "          callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncate = maxlen\n",
    "Z = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original = [f[i] for i in range(maxlen)]\n",
    "predicted = [None for i in range(maxlen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(length_of_sequences - maxlen + 1):\n",
    "    z_ = Z[-1:]\n",
    "    y_ = model.predict(z_)\n",
    "    sequence_ = np.concatenate(\n",
    "        (z_.reshape(maxlen, n_in)[1:], y_),\n",
    "        axis=0).reshape(1, maxlen, n_in)\n",
    "    Z = np.append(Z, sequence_, axis=0)\n",
    "    predicted.append(y_.reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.figure()\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.plot(toy_problem(T, ampl=0), linestyle='dotted', color='#aaaaaa')\n",
    "plt.plot(original, linestyle='dashed', color='black')\n",
    "plt.plot(predicted, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
